{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ActorCriticLunarLander.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqZGoP3StCih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "819eb654-3827-480c-caaf-1f3d05d97667"
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[all] > /dev/null 2>&1\n",
        "\n",
        "!pip install Box2D\n",
        "!pip install box2d"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (46.1.3)\n",
            "Collecting Box2D\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/0b/d48d42dd9e19ce83a3fb4eee074e785b6c6ea612a2244dc2ef69427d338b/Box2D-2.3.10-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.2MB/s \n",
            "\u001b[?25hInstalling collected packages: Box2D\n",
            "Successfully installed Box2D-2.3.10\n",
            "Requirement already satisfied: box2d in /usr/local/lib/python3.6/dist-packages (2.3.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwyeVcUWu7fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from IPython import display as ipythondisplay\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V73JzLT3tZHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "978ba78b-e56a-427f-b800-986686a7c495"
      },
      "source": [
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "# if is_python: from IPython import display\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xdpyinfo was not found, X start can not be checked! Please install xdpyinfo!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Display cmd_param=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] cmd=['Xvfb', '-br', '-nolisten', 'tcp', '-screen', '0', '1400x900x24', ':1007'] oserror=None return_code=None stdout=\"None\" stderr=\"None\" timeout_happened=False>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ache6SLOtb_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "innirRJ-N0CY",
        "colab_type": "text"
      },
      "source": [
        "The “Critic” estimates the value function. This could be the action-value (the Q value) or state-value (the V value).\n",
        "\n",
        "The “Actor” updates the policy distribution in the direction suggested by the Critic (such as with policy gradients)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWd_HrN9t6rR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ActorCriticNetwork(nn.Module):\n",
        "  def __init__(self,alpha,input_dims,fc1_dims,fc2_dims,n_actions):\n",
        "    super(ActorCriticNetwork,self).__init__()\n",
        "    self.alpha = alpha\n",
        "    self.input_dims = input_dims\n",
        "    self.fc1_dims = fc1_dims\n",
        "    self.fc2_dims = fc2_dims\n",
        "    self.n_actions = n_actions\n",
        "    self.fc1 = nn.Linear(*self.input_dims,self.fc1_dims)\n",
        "    self.fc2 = nn.Linear(self.fc1_dims,self.fc2_dims)\n",
        "\n",
        "    self.pi = nn.Linear(self.fc2_dims,n_actions)\n",
        "    self.v = nn.Linear(self.fc2_dims,1)\n",
        "\n",
        "    self.optimizer = optim.Adam(self.parameters(),lr=self.alpha)\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    self.to(self.device)\n",
        "\n",
        "  def forward(self, observation):\n",
        "    state = torch.Tensor(observation).to(self.device)\n",
        "    x = F.relu(self.fc1(state))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    pi = self.pi(x)\n",
        "    v = self.v(x)\n",
        "\n",
        "    return pi,v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-Tmg0OpOJDw",
        "colab_type": "text"
      },
      "source": [
        "Here the agent chooses an action on the basis of the evaluation that the network makes when presented the current states of the environment.\n",
        "\n",
        "Thr Critic evaluates the actor's choice of action by evaluating the value function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YkJozhBteny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NewAgent(object):\n",
        "  def __init__(self,alpha,input_dims,gamma=0.99,layer1_size=256,layer2_size=256,n_actions=4):\n",
        "    self.gamma = gamma\n",
        "    self.actor_critic = ActorCriticNetwork(alpha,input_dims,layer1_size,layer2_size,n_actions=n_actions)\n",
        "    self.log_probs = None\n",
        "\n",
        "  def choose_action(self,observation):\n",
        "    policy,_ = self.actor_critic.forward(observation)\n",
        "    policy = F.softmax(policy)\n",
        "    action_probs = torch.distributions.Categorical(policy)\n",
        "    action = action_probs.sample()\n",
        "    self.log_probs = action_probs.log_prob(action)\n",
        "\n",
        "    return action.item()\n",
        "\n",
        "  def learn(self, state, reward, state_, done):\n",
        "    self.actor_critic.optimizer.zero_grad()\n",
        "\n",
        "    _,critic_value = self.actor_critic.forward(state)\n",
        "    _,critic_value_ = self.actor_critic.forward(state_)\n",
        "\n",
        "    reward = torch.tensor(reward, dtype=torch.float).to(self.actor_critic.device)\n",
        "    delta = reward + self.gamma*critic_value_*(1-int(done)) - critic_value\n",
        "\n",
        "    actor_loss = -self.log_probs*delta #gradient ascent so it is -ve\n",
        "    critic_loss = delta**2\n",
        "\n",
        "    (actor_loss+critic_loss).backward()\n",
        "    self.actor_critic.optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4G_3m8y5RZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(values,moving_avg_period):\n",
        "  plt.figure(2)\n",
        "  plt.clf()\n",
        "  plt.title('Training..')\n",
        "  plt.xlabel('Episode')\n",
        "  plt.ylabel('Duration')\n",
        "  plt.plot(values)\n",
        "  moving_avg = get_moving_average(moving_avg_period,values)\n",
        "  plt.plot(moving_avg)\n",
        "  plt.pause(0.001)\n",
        "  print(\"Episode\",len(values),\"\\n\",moving_avg_period,\"episode moving avg:\",moving_avg[-1])\n",
        "  if is_ipython: ipythondisplay.clear_output(wait=True)\n",
        "\n",
        "def get_moving_average(period,values):\n",
        "  values = torch.tensor(values,dtype=torch.float)\n",
        "  if len(values)>=period:\n",
        "    moving_avg = values.unfold(dimension=0, size=period,step=1).mean(dim=1).flatten(start_dim=0)\n",
        "    moving_avg = torch.cat((torch.zeros(period-1),moving_avg))\n",
        "    return moving_avg.numpy()\n",
        "  else:\n",
        "    moving_avg = torch.zeros(len(values))\n",
        "    return moving_avg.numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQR6F1ests8r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8153674b-5f0b-4d54-fdf5-95b77bf7c2a8"
      },
      "source": [
        "agent = NewAgent(alpha=0.00001, input_dims=[8], gamma=0.99, n_actions=4,layer1_size=2048,layer2_size=512)\n",
        "\n",
        "env = wrap_env(gym.make('LunarLander-v2').unwrapped)\n",
        "score_history = []\n",
        "num_episodes = 2000\n",
        "\n",
        "for i in range(num_episodes):\n",
        "  done = False\n",
        "  observation = env.reset()\n",
        "  score = 0\n",
        "  while not done:\n",
        "    action = agent.choose_action(observation)\n",
        "    observation_,reward,done,info = env.step(action)\n",
        "    agent.learn(observation,reward,observation_,done)\n",
        "    observation = observation_\n",
        "    score+=reward\n",
        "\n",
        "  score_history.append(score)\n",
        "  # print(\"episode\",i,\"score %.2f\" %score)\n",
        "  plot(score_history,100)\n",
        "\n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNeDTnOf9jOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}